{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6494011,"sourceType":"datasetVersion","datasetId":3753245}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<font size=\"10\">**Extracting Date and Total from Receipts Using pytesseract and easy_ocr**</font>\n\n\n<font size=\"6\">\nThe images are first imported, then for both pytesseract and easy_ocr, the following steps are followed:\n</font>\n\n<font size=\"6\">\n   \n1. Obtain all the text from the images \n1. Extract the date using regex\n1. Extract the total price using regex\n1. Create a pandas dataframe with the image name, raw text extracted, date and total\n</font>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T21:39:06.958256Z","iopub.execute_input":"2024-04-26T21:39:06.958725Z","iopub.status.idle":"2024-04-26T21:39:07.375084Z","shell.execute_reply.started":"2024-04-26T21:39:06.958689Z","shell.execute_reply":"2024-04-26T21:39:07.373496Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport pytesseract\nimport matplotlib.pyplot as plt\nimport glob\nimport os \nimport re\n\nprint(os.getcwd())\n\ndef Display_Image(image, title = 'an image'):\n    plt.imshow(image)\n    plt.title(title)\n    plt.show()\n    plt.clf()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:39:07.377424Z","iopub.execute_input":"2024-04-26T21:39:07.378832Z","iopub.status.idle":"2024-04-26T21:39:07.399236Z","shell.execute_reply.started":"2024-04-26T21:39:07.378789Z","shell.execute_reply":"2024-04-26T21:39:07.395043Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n'''\nImport the data\n'''\n\nprint(os.getcwd())\nlist_images = glob.glob(r\"/kaggle/input/ocr-receipts-text-detection/images/*.jpg\")\nprint(len(list_images))\n\nimages = np.array([np.array(Image.open(fname))\\\n                   for fname in list_images], dtype = \"object\")\nprint(images.shape)\nprint(images[0].shape)\n\n# Let's display a handfull of images\nfor i in range(len(images)):\n    if i%3 == 0:\n        Display_Image(images[i], title = 'image #' + str(i))\n# As we can see, some images are of better quality than others","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:39:07.401257Z","iopub.execute_input":"2024-04-26T21:39:07.401615Z","iopub.status.idle":"2024-04-26T21:39:11.545869Z","shell.execute_reply.started":"2024-04-26T21:39:07.401582Z","shell.execute_reply":"2024-04-26T21:39:11.544885Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with pytesseract and data processing, Part I\n'''\n# Feed each image into pytesseract to extract text,\n# then extract the date and the total amount of each receipt\n\n# Simple test\nprint(pytesseract.image_to_string(images[3], lang = 'eng'))\n# looking good!\n\n# Full run, takes a few minutes\nraw_text = [pytesseract.image_to_string(images[i], lang = 'eng') for i in range(len(images))]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:39:11.547718Z","iopub.execute_input":"2024-04-26T21:39:11.548003Z","iopub.status.idle":"2024-04-26T21:40:21.896406Z","shell.execute_reply.started":"2024-04-26T21:39:11.54798Z","shell.execute_reply":"2024-04-26T21:40:21.895208Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[print(len(raw_text[i])) for i in range(len(raw_text))]\n# Not a lot has been extracted from the 2nd and 3rd images, \n# Let's have a closer look\n\nDisplay_Image(images[1], title = 'image #1')\nDisplay_Image(images[2], title = 'image #2')\n# That is fair that the algorithum is struggling, those are saturated and blurry pictures","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:40:21.897918Z","iopub.execute_input":"2024-04-26T21:40:21.898308Z","iopub.status.idle":"2024-04-26T21:40:22.446675Z","shell.execute_reply.started":"2024-04-26T21:40:21.898277Z","shell.execute_reply":"2024-04-26T21:40:22.445463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with pytesseract and data processing, Part II\n'''\n# Extract the date and total from text pytesseract extracted from the images\n\n# Let's extract the dates format from raw text\n# Trader joe's date format: mm-dd-yyyy\n# Walmart date format: mm/dd/yy\n# WholeFood: mm/dd/yyyy\n# Spar: dd.mm.yy\n# WinCo Food: mm/dd/yy\n# Costco: mm/dd/yyyy\n# MOMI & TOY's: dd/mm/yyyy\n#\n# a few format stands out:\n# number: #\n#   ##-##-#### regex: \\d\\d+-+\\d\\d+-+\\d\\d\\d\\d\n#   ##/##/#### regex: \n#   ##.##.##\n#   ##/##/##\n#\n# regex: \\d\\d+[-/.]+\\d\\d+[-/.]+\\d\\d\\d\\d\n# regex: \\d\\d+[-/.]+\\d\\d+[-/.]+\\d\\d\\D\n# Those 2 functions should conver all the format above!\n#\n# I ended up creating a regex function that combines the 2 above,\n# Final regex: \\d{2}[.\\/-]\\d{2}[.\\/-]\\d{2,4}\n\n# Function to search for dates within the raw_text\n#\ndef Date_Extraction(text):\n    temp = re.findall(\"\\d{2}[.\\/-]\\d{2}[.\\/-]\\d{2,4}\", text)\n    temp = pd.Series(temp)\n    temp = list(temp.unique())\n    \n    return temp\n    \n\nDate_Extraction(raw_text[0]) \n\ndate = [Date_Extraction(text) for text in raw_text]\nprint(date)\n\n\n# Function to search for total price \n#\n\ndef Total_Extraction(text):\n    try:\n        test = pd.Series(re.split(\"\\n\",text ))\n        value = test[test.str.find('TOTAL')==0].reset_index(drop = True)    \n        num = float(re.sub(\"[^\\d.]\", \"\", value[0]))\n        return num\n    except:\n        return None\n\ntotal = [Total_Extraction(text) for text in raw_text]\n\nprint(total)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:40:22.448072Z","iopub.execute_input":"2024-04-26T21:40:22.44842Z","iopub.status.idle":"2024-04-26T21:40:22.483832Z","shell.execute_reply.started":"2024-04-26T21:40:22.448393Z","shell.execute_reply":"2024-04-26T21:40:22.482333Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with pytesseract and data processing Part III\n'''\n# Create a data frame with all the information gathered\n\n# Get the image's names\nimages_name = [list_images[i].split('/')[-1] for i in range(len(images))]\n\ndata_extraction_pytesseract = pd.DataFrame( {\n                                'image': images_name\n                                ,'raw_text': raw_text\n                                ,'date': date\n                                ,'total': total\n                                })\ndata_extraction_pytesseract","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:40:22.485161Z","iopub.execute_input":"2024-04-26T21:40:22.485432Z","iopub.status.idle":"2024-04-26T21:40:22.517596Z","shell.execute_reply.started":"2024-04-26T21:40:22.485412Z","shell.execute_reply":"2024-04-26T21:40:22.516183Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with easy_ocr and data processing, Part I\n'''\n\nimport easyocr\n\nreader = easyocr.Reader(['en'], gpu = False)\n\nDisplay_Image(images[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:40:22.519143Z","iopub.execute_input":"2024-04-26T21:40:22.519494Z","iopub.status.idle":"2024-04-26T21:40:33.809998Z","shell.execute_reply.started":"2024-04-26T21:40:22.519461Z","shell.execute_reply":"2024-04-26T21:40:33.808464Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with easy_ocr and data processing, Part II\n'''\ntext = reader.readtext(images[0])\nprint(text)\n# The format is quite different that with pytesseract!\n\nall_text = [reader.readtext(images[im]) for im in range(len(images))]","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:40:33.811784Z","iopub.execute_input":"2024-04-26T21:40:33.81231Z","iopub.status.idle":"2024-04-26T21:44:08.535953Z","shell.execute_reply.started":"2024-04-26T21:40:33.81228Z","shell.execute_reply":"2024-04-26T21:44:08.534807Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with easy_ocr and data processing, Part III\n'''\ndef Easyocr_Total_Extraction(text):\n    # Isolate teh text, exclude the box and the accuracy values\n    sub_text = pd.DataFrame(text)[1]\n    \n    # Turn everything into a single string\n    sub_text = ' '.join(sub_text)\n    sub_text = sub_text.upper()\n\n    # Find the find the set of number and some characters following teh word 'TOTAL'\n    # while excluding 'SUBTOTAL'\n    amount = re.findall(r\"((?<=TOTAL\\s)[$,.0-9]+)\", sub_text)\n    \n    try:\n        # get rid of the dollard sign and ouput a float\n        amount = re.findall(r\"([0-9.,]+)\", amount[0])\n        return float(amount[0])\n    except:\n        return None\n\nprint(len(all_text[0]))\n\n\ntotals = [Easyocr_Total_Extraction(all_text[im]) for im in range(len(all_text))]\nprint(totals)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:52:34.286688Z","iopub.execute_input":"2024-04-26T21:52:34.287063Z","iopub.status.idle":"2024-04-26T21:52:34.302485Z","shell.execute_reply.started":"2024-04-26T21:52:34.287036Z","shell.execute_reply":"2024-04-26T21:52:34.300479Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with easy_ocr and data processing, Part IV\n'''\n# Let's extract the date\n\ndef Easyocr_Date_Extraction(text):\n    sub_text = pd.DataFrame(text)[1]\n\n    sub_text = ' '.join(sub_text)\n    sub_text = sub_text.upper()\n\n    date = re.findall(r\"(\\d{2}[.\\/-]\\d{2}[.\\/-]\\d{2,4})\", sub_text)\n    \n    try:\n        return date[0]\n    except:\n        return None\n\ndates = [(Easyocr_Date_Extraction(all_text[im])) for im in range(len(all_text))]\nprint(dates)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:53:04.185074Z","iopub.execute_input":"2024-04-26T21:53:04.18548Z","iopub.status.idle":"2024-04-26T21:53:04.199957Z","shell.execute_reply.started":"2024-04-26T21:53:04.185451Z","shell.execute_reply":"2024-04-26T21:53:04.198654Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nText extraction with easy_ocr and data processing, Part V\n'''\ndata_extraction_easyocr = pd.DataFrame( {\n                                'image': images_name\n                                ,'raw_text': all_text\n                                ,'date': dates\n                                ,'total': totals\n                                })\ndata_extraction_easyocr","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:53:37.551075Z","iopub.execute_input":"2024-04-26T21:53:37.55147Z","iopub.status.idle":"2024-04-26T21:53:38.193368Z","shell.execute_reply.started":"2024-04-26T21:53:37.551433Z","shell.execute_reply":"2024-04-26T21:53:38.191884Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"MY CODE\n","metadata":{}},{"cell_type":"code","source":"!pip install easyocr\n!apt install tesseract-ocr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:48:35.901354Z","iopub.execute_input":"2025-06-24T19:48:35.901764Z","iopub.status.idle":"2025-06-24T19:49:25.159877Z","shell.execute_reply.started":"2025-06-24T19:48:35.901715Z","shell.execute_reply":"2025-06-24T19:49:25.158510Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: easyocr in /opt/conda/lib/python3.10/site-packages (1.7.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from easyocr) (2.1.2+cpu)\nRequirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.16.2+cpu)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from easyocr) (4.9.0.80)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.11.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from easyocr) (9.5.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.22.0)\nRequirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.4.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from easyocr) (6.0.1)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.8.5.post1)\nRequirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.3.0.post5)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.11.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5->easyocr) (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (2024.2.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from python-bidi->easyocr) (1.16.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2023.12.9)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (21.3)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->easyocr) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->easyocr) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->easyocr) (1.3.0)\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2build2).\n0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageEnhance\nimport pytesseract\nimport easyocr\nimport matplotlib.pyplot as plt\nimport glob\nimport os \nimport re\nimport cv2\nimport json\nfrom scipy import ndimage\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:49:40.098314Z","iopub.execute_input":"2025-06-24T19:49:40.098675Z","iopub.status.idle":"2025-06-24T19:49:45.887779Z","shell.execute_reply.started":"2025-06-24T19:49:40.098643Z","shell.execute_reply":"2025-06-24T19:49:45.886313Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def preprocess_image(image):\n    if isinstance(image, Image.Image):\n        image = np.array(image)\n    \n    if len(image.shape) == 3:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image.copy()\n    \n    gray_corrected = correct_skew(gray)\n    enhanced = cv2.equalizeHist(gray_corrected)\n    denoised = cv2.medianBlur(enhanced, 3)\n    kernel = np.ones((1,1), np.uint8)\n    cleaned = cv2.morphologyEx(denoised, cv2.MORPH_CLOSE, kernel)\n    \n    return cleaned\n\ndef correct_skew(image):\n    try:\n        edges = cv2.Canny(image, 50, 150, apertureSize=3)\n        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n        \n        if lines is not None:\n            angles = []\n            for rho, theta in lines[:10]:\n                angle = theta * 180 / np.pi\n                if angle > 45:\n                    angle = angle - 90\n                angles.append(angle)\n            \n            median_angle = np.median(angles)\n            if abs(median_angle) > 0.5:\n                rotated = ndimage.rotate(image, median_angle, reshape=False, cval=255)\n                return rotated\n        \n        return image\n    except:\n        return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:49:54.526637Z","iopub.execute_input":"2025-06-24T19:49:54.527149Z","iopub.status.idle":"2025-06-24T19:49:54.536626Z","shell.execute_reply.started":"2025-06-24T19:49:54.527119Z","shell.execute_reply":"2025-06-24T19:49:54.535478Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def detect_printed_area(image):\n    try:\n        if len(image.shape) == 3:\n            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        else:\n            gray = image.copy()\n        \n        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        if contours:\n            largest_contour = max(contours, key=cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(largest_contour)\n            padding = 20\n            x = max(0, x - padding)\n            y = max(0, y - padding)\n            w = min(gray.shape[1] - x, w + 2 * padding)\n            h = min(gray.shape[0] - y, h + 2 * padding)\n            cropped = image[y:y+h, x:x+w]\n            return cropped\n        \n        return image\n    except:\n        return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:50:20.035398Z","iopub.execute_input":"2025-06-24T19:50:20.035757Z","iopub.status.idle":"2025-06-24T19:50:20.044327Z","shell.execute_reply.started":"2025-06-24T19:50:20.035732Z","shell.execute_reply":"2025-06-24T19:50:20.043123Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def extract_merchant_name_pytesseract(text):\n    lines = text.strip().split('\\n')\n    merchant_keywords = [\n        'TRADER JOE', 'WALMART', 'WHOLE FOODS', 'COSTCO', 'SAFEWAY', 'KROGER',\n        'TARGET', 'CVS', 'WALGREENS', 'MCDONALD', 'STARBUCKS', 'SUBWAY',\n        'SPAR', 'WINCO', 'MOMI', 'TOY', 'STORE', 'MARKET', 'SHOP'\n    ]\n    for i, line in enumerate(lines[:5]):\n        line_upper = line.upper().strip()\n        if len(line_upper) < 3 or re.search(r'^\\d+[\\d\\s\\-/]*$', line_upper):\n            continue\n        for keyword in merchant_keywords:\n            if keyword in line_upper:\n                cleaned = re.sub(r'[^\\w\\s&\\'-]', ' ', line_upper)\n                return ' '.join(cleaned.split())\n        if i == 0 and len(line_upper) > 3:\n            cleaned = re.sub(r'[^\\w\\s&\\'-]', ' ', line_upper)\n            return ' '.join(cleaned.split())\n    return None\n\ndef extract_merchant_name_easyocr(text_data):\n    if not text_data:\n        return None\n    texts = [item[1] for item in text_data]\n    merchant_keywords = [\n        'TRADER JOE', 'WALMART', 'WHOLE FOODS', 'COSTCO', 'SAFEWAY', 'KROGER',\n        'TARGET', 'CVS', 'WALGREENS', 'MCDONALD', 'STARBUCKS', 'SUBWAY',\n        'SPAR', 'WINCO', 'MOMI', 'TOY', 'STORE', 'MARKET', 'SHOP'\n    ]\n    for i, text in enumerate(texts[:5]):\n        text_upper = text.upper().strip()\n        if len(text_upper) < 3 or re.search(r'^\\d+[\\d\\s\\-/]*$', text_upper):\n            continue\n        for keyword in merchant_keywords:\n            if keyword in text_upper:\n                cleaned = re.sub(r'[^\\w\\s&\\'-]', ' ', text_upper)\n                return ' '.join(cleaned.split())\n        if i == 0 and len(text_upper) > 3:\n            cleaned = re.sub(r'[^\\w\\s&\\'-]', ' ', text_upper)\n            return ' '.join(cleaned.split())\n    return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:50:37.105054Z","iopub.execute_input":"2025-06-24T19:50:37.106071Z","iopub.status.idle":"2025-06-24T19:50:37.117154Z","shell.execute_reply.started":"2025-06-24T19:50:37.106028Z","shell.execute_reply":"2025-06-24T19:50:37.116098Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def extract_total_pytesseract(text):\n    try:\n        lines = text.split('\\n')\n        for line in lines:\n            line_upper = line.upper().strip()\n            if line_upper.startswith('TOTAL'):\n                numbers = re.findall(r'\\d+\\.?\\d*', line)\n                if numbers:\n                    amounts = [float(num) for num in numbers if '.' in num or len(num) >= 2]\n                    if amounts:\n                        return max(amounts)\n        text_upper = text.upper()\n        total_matches = re.findall(r'TOTAL[^\\d]*(\\d+\\.?\\d{2})', text_upper)\n        if total_matches:\n            return float(total_matches[-1])\n        total_pattern = re.search(r'TOTAL[^\\d]*\\$?(\\d+\\.\\d{2})', text_upper)\n        if total_pattern:\n            return float(total_pattern.group(1))\n        all_amounts = re.findall(r'\\$?(\\d+\\.\\d{2})', text)\n        if all_amounts:\n            return max([float(a) for a in all_amounts])\n        return None\n    except:\n        return None\n\ndef extract_total_easyocr(text_data):\n    try:\n        if not text_data:\n            return None\n        texts = [item[1] for item in text_data]\n        combined_text = ' '.join(texts).upper()\n        total_pattern = re.search(r'TOTAL[^\\d]*\\$?(\\d+\\.?\\d{2})', combined_text)\n        if total_pattern:\n            return float(total_pattern.group(1))\n        for text in texts:\n            text_upper = text.upper().strip()\n            if 'TOTAL' in text_upper:\n                numbers = re.findall(r'\\d+\\.\\d{2}', text_upper)\n                if numbers:\n                    return float(numbers[-1])\n        all_amounts = re.findall(r'\\$?(\\d+\\.\\d{2})', combined_text)\n        if all_amounts:\n            return max([float(a) for a in all_amounts])\n        return None\n    except:\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:50:53.968402Z","iopub.execute_input":"2025-06-24T19:50:53.968759Z","iopub.status.idle":"2025-06-24T19:50:53.980124Z","shell.execute_reply.started":"2025-06-24T19:50:53.968735Z","shell.execute_reply":"2025-06-24T19:50:53.978908Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def process_receipts_pipeline():\n    list_images = glob.glob(r\"/kaggle/input/ocr-receipts-text-detection/images/*.jpg\")\n    print(f\"Found {len(list_images)} images to process\")\n    \n    reader = easyocr.Reader(['en'], gpu=False)\n    results = []\n\n    for i, image_path in enumerate(list_images):\n        print(f\"Processing image {i+1}/{len(list_images)}: {os.path.basename(image_path)}\")\n        try:\n            image = np.array(Image.open(image_path))\n            cropped_image = detect_printed_area(image)\n            processed_image = preprocess_image(cropped_image)\n\n            pytess_text = pytesseract.image_to_string(processed_image, lang='eng')\n            pytess_merchant = extract_merchant_name_pytesseract(pytess_text)\n            pytess_total = extract_total_pytesseract(pytess_text)\n\n            easyocr_result = reader.readtext(processed_image)\n            easyocr_merchant = extract_merchant_name_easyocr(easyocr_result)\n            easyocr_total = extract_total_easyocr(easyocr_result)\n\n            if pytess_merchant and pytess_total:\n                merchant_name = pytess_merchant\n                total_amount = pytess_total\n                ocr_engine = \"pytesseract\"\n            elif easyocr_merchant and easyocr_total:\n                merchant_name = easyocr_merchant\n                total_amount = easyocr_total\n                ocr_engine = \"easyocr\"\n            else:\n                merchant_name = pytess_merchant or easyocr_merchant\n                total_amount = pytess_total or easyocr_total\n                ocr_engine = \"hybrid\"\n\n            results.append({\n                \"image\": os.path.basename(image_path),\n                \"merchant_name\": merchant_name,\n                \"total_amount\": total_amount,\n                \"ocr_engine_used\": ocr_engine\n            })\n\n            print(f\"  Merchant: {merchant_name}\")\n            print(f\"  Total: ${total_amount}\")\n            print()\n        except Exception as e:\n            print(f\"Error processing {image_path}: {str(e)}\")\n            results.append({\n                \"image\": os.path.basename(image_path),\n                \"merchant_name\": None,\n                \"total_amount\": None,\n                \"ocr_engine_used\": \"error\"\n            })\n    \n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:51:30.743833Z","iopub.execute_input":"2025-06-24T19:51:30.744226Z","iopub.status.idle":"2025-06-24T19:51:30.754745Z","shell.execute_reply.started":"2025-06-24T19:51:30.744177Z","shell.execute_reply":"2025-06-24T19:51:30.753488Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def save_results_to_json(results, filename=\"ocr_results.json\"):\n    json_results = [{\n        \"image\": r[\"image\"],\n        \"merchant_name\": r[\"merchant_name\"],\n        \"total_amount\": r[\"total_amount\"]\n    } for r in results]\n    \n    with open(filename, 'w') as f:\n        json.dump(json_results, f, indent=2)\n    \n    print(f\"Results saved to {filename}\")\n    return json_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:51:43.912579Z","iopub.execute_input":"2025-06-24T19:51:43.913054Z","iopub.status.idle":"2025-06-24T19:51:43.921231Z","shell.execute_reply.started":"2025-06-24T19:51:43.913020Z","shell.execute_reply":"2025-06-24T19:51:43.919947Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"results = process_receipts_pipeline()\njson_results = save_results_to_json(results)\n\ndf = pd.DataFrame(results)\nprint(\"\\nResults Summary:\")\nprint(df[['image', 'merchant_name', 'total_amount', 'ocr_engine_used']])\n\nsuccessful_merchant = df['merchant_name'].notna().sum()\nsuccessful_total = df['total_amount'].notna().sum()\ntotal_images = len(df)\n\nprint(f\"\\nSuccess Rates:\")\nprint(f\"Merchant Name: {successful_merchant}/{total_images} ({successful_merchant/total_images*100:.1f}%)\")\nprint(f\"Total Amount: {successful_total}/{total_images} ({successful_total/total_images*100:.1f}%)\")\nprint(f\"Both Fields: {df.dropna(subset=['merchant_name', 'total_amount']).shape[0]}/{total_images}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T19:51:56.033918Z","iopub.execute_input":"2025-06-24T19:51:56.035172Z","iopub.status.idle":"2025-06-24T19:56:48.143858Z","shell.execute_reply.started":"2025-06-24T19:51:56.035129Z","shell.execute_reply":"2025-06-24T19:56:48.142799Z"}},"outputs":[{"name":"stdout","text":"Found 19 images to process\nProcessing image 1/19: 5.jpg\n  Merchant: WHOLE FOODS\n  Total: $28.28\n\nProcessing image 2/19: 8.jpg\n  Merchant: None\n  Total: $None\n\nProcessing image 3/19: 10.jpg\n  Merchant: BEER 036-4481240\n  Total: $15.99\n\nProcessing image 4/19: 0.jpg\n  Merchant: WAL MART '\n  Total: $8348.64\n\nProcessing image 5/19: 9.jpg\n  Merchant: WINCO\n  Total: $121.92\n\nProcessing image 6/19: 1.jpg\n  Merchant: 2001 GREENYI1IE AVE\n  Total: $200.69\n\nProcessing image 7/19: 16.jpg\n  Merchant: EFT DEBIT PAY FROM PRIMARY\n  Total: $2696.0\n\nProcessing image 8/19: 7.jpg\n  Merchant: EFT DEBIT PAY FROM PRIMARY\n  Total: $2696.0\n\nProcessing image 9/19: 13.jpg\n  Merchant: ID A 1SWOVEXCW\n  Total: $10.0\n\nProcessing image 10/19: 17.jpg\n  Merchant: WP RSA\n  Total: $None\n\nProcessing image 11/19: 15.jpg\n  Merchant: WALMART\n  Total: $70.63\n\nProcessing image 12/19: 12.jpg\n  Merchant: WALAMART\n  Total: $13.48\n\nProcessing image 13/19: 11.jpg\n  Merchant: WHOLE\n  Total: $2.15\n\nProcessing image 14/19: 4.jpg\n  Merchant: WALMART\n  Total: $None\n\nProcessing image 15/19: 3.jpg\n  Merchant: BERT F\n  Total: $None\n\nProcessing image 16/19: 19.jpg\n  Merchant: GIVC U3\n  Total: $676.94\n\nProcessing image 17/19: 14.jpg\n  Merchant: SEE BACK OF RECEIPT FOR YOUR CHANCE\n  Total: $26.6\n\nProcessing image 18/19: 18.jpg\n  Merchant: DC YPRE\n  Total: $82.75\n\nProcessing image 19/19: 2.jpg\n  Merchant: GIVE US FOODBECK SURVEY WALMART COM\n  Total: $6.44\n\nResults saved to ocr_results.json\n\nResults Summary:\n     image                        merchant_name  total_amount ocr_engine_used\n0    5.jpg                          WHOLE FOODS         28.28     pytesseract\n1    8.jpg                                 None           NaN          hybrid\n2   10.jpg                     BEER 036-4481240         15.99     pytesseract\n3    0.jpg                           WAL MART '       8348.64         easyocr\n4    9.jpg                                WINCO        121.92         easyocr\n5    1.jpg                  2001 GREENYI1IE AVE        200.69     pytesseract\n6   16.jpg           EFT DEBIT PAY FROM PRIMARY       2696.00     pytesseract\n7    7.jpg           EFT DEBIT PAY FROM PRIMARY       2696.00     pytesseract\n8   13.jpg                       ID A 1SWOVEXCW         10.00     pytesseract\n9   17.jpg                               WP RSA           NaN          hybrid\n10  15.jpg                              WALMART         70.63         easyocr\n11  12.jpg                             WALAMART         13.48         easyocr\n12  11.jpg                                WHOLE          2.15         easyocr\n13   4.jpg                              WALMART           NaN          hybrid\n14   3.jpg                               BERT F           NaN          hybrid\n15  19.jpg                              GIVC U3        676.94         easyocr\n16  14.jpg  SEE BACK OF RECEIPT FOR YOUR CHANCE         26.60     pytesseract\n17  18.jpg                              DC YPRE         82.75     pytesseract\n18   2.jpg  GIVE US FOODBECK SURVEY WALMART COM          6.44     pytesseract\n\nSuccess Rates:\nMerchant Name: 18/19 (94.7%)\nTotal Amount: 15/19 (78.9%)\nBoth Fields: 15/19\n","output_type":"stream"}],"execution_count":14}]}